{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf4e10b",
   "metadata": {},
   "source": [
    "# 词向量探索之旅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db47534",
   "metadata": {},
   "source": [
    "### 环境准备\n",
    "\n",
    "确保已将 `histwords` 目录加入 `PYTHONPATH`，并已安装依赖。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17989714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/workspace/MicroDistanc-Word2Vec/histwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da512b",
   "metadata": {},
   "source": [
    "## 1. 从斯坦福大学HistWords项目中获取词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6744322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# 加载词表\n",
    "with open('/root/workspace/MicroDistanc-Word2Vec/Chinese_sgns_basic/1990-vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "# 加载词向量\n",
    "vecs = np.load('/root/workspace/MicroDistanc-Word2Vec/Chinese_sgns_basic/1990-w.npy')\n",
    "\n",
    "# 获取某个词的向量\n",
    "words = ['病毒', '电脑', '疾病', '计算机']\n",
    "for word in words:\n",
    "    if word in vocab:\n",
    "        idx = vocab.index(word)\n",
    "        vector = vecs[idx]\n",
    "        print(vector.shape) # 输出向量维度\n",
    "    else:\n",
    "        print('词不在词表中')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefcb63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "病毒 - 电脑 的余弦相似度: 0.2628\n",
      "病毒 - 疾病 的余弦相似度: 0.3643\n",
      "病毒 - 计算机 的余弦相似度: 0.3050\n",
      "电脑 - 疾病 的余弦相似度: 0.1756\n",
      "电脑 - 计算机 的余弦相似度: 0.4383\n",
      "疾病 - 计算机 的余弦相似度: 0.1918\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# 获取所有在词表中的词及其向量\n",
    "word_vecs = {}\n",
    "for word in words:\n",
    "    if word in vocab:\n",
    "        idx = vocab.index(word)\n",
    "        word_vecs[word] = vecs[idx]\n",
    "\n",
    "# 计算两两余弦相似度\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "for w1, w2 in combinations(word_vecs.keys(), 2):\n",
    "    sim = cosine_similarity(word_vecs[w1], word_vecs[w2])\n",
    "    print(f\"{w1} - {w2} 的余弦相似度: {sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a44aef",
   "metadata": {},
   "source": [
    "## 调用HistWords提供的API端口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41674f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "from representations.sequentialembedding import SequentialEmbedding\n",
    "from representations.embedding import Embedding\n",
    "# SequentialEmbedding是Word2Vec（SGNS）词向量\n",
    "# Embedding是SVD词向量\n",
    "\n",
    "# 加载词向量：单一时间点\n",
    "embedding = Embedding.load('/root/workspace/MicroDistanc-Word2Vec/Chinese_sgns_basic/1990')\n",
    "# 获取词向量\n",
    "vector = embedding.represent('病毒')\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cc920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学者 0.9999999999999999\n",
      "专家 0.6019439454234679\n",
      "名望 0.5160167174959029\n",
      "业内 0.49601799256692675\n",
      "与会 0.45654864865628536\n"
     ]
    }
   ],
   "source": [
    "neighbors = embedding.closest('学者', n=5)\n",
    "for score, word in neighbors:\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c17a99",
   "metadata": {},
   "source": [
    "## 历史模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27276e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.1 加载历史词向量序列\n",
    "\n",
    "from representations.sequentialembedding import SequentialEmbedding\n",
    "years = range(1950, 2000, 10)\n",
    "semb = SequentialEmbedding.load('/root/workspace/MicroDistanc-Word2Vec/chi-sim-all/sgns', years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e19dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.2 获取某一年份的 Embedding\n",
    "\n",
    "embed_1990 = semb.get_embed(1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "170b0baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 [-0.04487927  0.02573186 -0.00947995 -0.03877381  0.03205856]\n",
      "1960 [ 0.00161559  0.04229061 -0.0445441  -0.02257752  0.06220378]\n",
      "1970 [-0.00346575  0.0531096  -0.09491494 -0.03063736  0.01986805]\n",
      "1980 [-0.00850022 -0.02292808 -0.06003177 -0.04335207  0.04974374]\n",
      "1990 [-0.01324701  0.0365957   0.01875553 -0.0736503   0.09564648]\n"
     ]
    }
   ],
   "source": [
    "### 3.3 获取某个词在各年份的向量\n",
    "\n",
    "for year in years:\n",
    "    vec = semb.get_embed(year).represent('主义')\n",
    "    print(year, vec[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd6eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 0.4552571961323729\n",
      "1960 0.4420168275879869\n",
      "1970 0.1762702730146145\n",
      "1980 0.12860420820157537\n",
      "1990 0.1581925143538493\n"
     ]
    }
   ],
   "source": [
    "### 3.4 计算某两个词随时间的相似度变化\n",
    "\n",
    "time_sims = semb.get_time_sims('学术', '反动')\n",
    "for year, sim in time_sims.items():\n",
    "    print(year, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b28709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'资产', '腐朽', '流毒', '残酷', '猖狂', '反动'}\n"
     ]
    }
   ],
   "source": [
    "### 3.5 获取某个词在所有年份的邻居集合\n",
    "\n",
    "neigh_set = semb.get_seq_neighbour_set('反动', n=2)\n",
    "print(neigh_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee339759",
   "metadata": {},
   "source": [
    "## 读取词性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eedc285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文人: NOUN\n",
      "作家: NOUN\n",
      "反动: ADJ\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pos_file = '/root/workspace/MicroDistanc-Word2Vec/chi-sim-all/pos/1990-pos.pkl'\n",
    "with open(pos_file, 'rb') as f:\n",
    "    pos_dict = pickle.load(f)\n",
    "\n",
    "# 示例：提取指定词的词性\n",
    "target_words = ['文人', '作家', '反动']\n",
    "for word in target_words:\n",
    "    print(f\"{word}: {pos_dict.get(word, '未知')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性标签表\n",
    "\n",
    "| 类别       | NOUN | VERB | ADV | ADJ | PRT           | NUM |\n",
    "|------------|------|------|-----|------|---------|-----|\n",
    "| 含义 | 名词 | 动词 | 副词 | 形容词 | 小品词| 数词 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dbe54e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "流毒 0.4868973151790801\n",
      "统治 0.469506656018562\n",
      "反动派 0.4544083060623153\n",
      "山头 0.4390510906423339\n",
      "势力 0.4244963574685242\n"
     ]
    }
   ],
   "source": [
    "# 按照词性筛选邻居\n",
    "\n",
    "def get_neighbor_with_pos(embed: Embedding, pos_dict: dict, target_word: str, target_pos: str, n=10):\n",
    "    \"\"\"\n",
    "    获取与 target_word 最相近且词性为 target_pos 的前 n 个词。\n",
    "    \"\"\"\n",
    "    # 获取所有邻居及分数\n",
    "    neighbors = embed.closest(target_word, n=n*5)  # 先多取一些，防止词性过滤后不够\n",
    "    filtered = []\n",
    "    for score, word in neighbors:\n",
    "        if pos_dict.get(word) == target_pos:\n",
    "            filtered.append((score, word))\n",
    "        if len(filtered) >= n:\n",
    "            break\n",
    "    return filtered\n",
    "\n",
    "# 示例用法：\n",
    "result = get_neighbor_with_pos(embedding, pos_dict, '反动', 'NOUN', n=5)\n",
    "for score, word in result:\n",
    "    print(word, score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915dd293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1950: [(0.9999999999999998, '钱'),\n",
       "  (0.9038659420271383, '花'),\n",
       "  (0.835149942616815, '人家'),\n",
       "  (0.8337984704298391, '买'),\n",
       "  (0.8294886079513678, '吃')],\n",
       " 1960: [(1.0, '钱'),\n",
       "  (0.7650870282192708, '花'),\n",
       "  (0.7129815339097929, '一声'),\n",
       "  (0.6971985912410859, '口气'),\n",
       "  (0.6760362568782627, '这儿')],\n",
       " 1970: [(0.9999999999999993, '钱'),\n",
       "  (0.5850082522695432, '买'),\n",
       "  (0.5524397898584145, '笔'),\n",
       "  (0.5367441157010124, '花'),\n",
       "  (0.5156797911524045, '力气')],\n",
       " 1980: [(1.0, '钱'),\n",
       "  (0.5349853096138412, '赚'),\n",
       "  (0.5055068782570069, '花'),\n",
       "  (0.47393366638954987, '袋'),\n",
       "  (0.471501573268131, '琛')],\n",
       " 1990: [(1.0, '钱'),\n",
       "  (0.4587084023580492, '袋'),\n",
       "  (0.45845257084407204, '掏'),\n",
       "  (0.44759882378635524, '赚'),\n",
       "  (0.4351914162230578, '抽屉')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取历年的邻居集合（不筛选词性）\n",
    "\n",
    "semb.get_seq_closest_by_year(\"钱\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc5c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_neighbor_with_pos(seqembed: SequentialEmbedding, pos_dict: dict, target_word: str, target_pos: str, n=10):\n",
    "    \"\"\"\n",
    "    获取目标词在每个年份中，最相近且词性为 target_pos 的前 n 个词。\n",
    "    返回格式：{year: [(score, word), ...], ...}\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for year, embed in seqembed.embeds.items():\n",
    "        neighbors = embed.closest(target_word, n=n*100)  # 先多取一些\n",
    "        filtered = []\n",
    "        for score, word in neighbors:\n",
    "            if pos_dict.get(word) == target_pos and word != target_word:\n",
    "                filtered.append((score, word))\n",
    "            if len(filtered) >= n:\n",
    "                break\n",
    "        result[year] = filtered\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f504632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1950: [(0.7484916568501956, '年轻'),\n",
       "  (0.698449745027883, '女'),\n",
       "  (0.5980052306407435, '亲爱'),\n",
       "  (0.5614793955077362, '违法'),\n",
       "  (0.5436568614143564, '间接')],\n",
       " 1960: [(0.5316574658520359, '女'),\n",
       "  (0.5078091283696169, '年轻'),\n",
       "  (0.4924626804071737, '相关'),\n",
       "  (0.4663310115925252, '亲爱'),\n",
       "  (0.4641558590600444, '有限')],\n",
       " 1970: [(0.4098309110734928, '男'),\n",
       "  (0.3945802598299771, '女'),\n",
       "  (0.3754188716391379, '年轻'),\n",
       "  (0.3684000505355881, '优质'),\n",
       "  (0.35792361677380874, '可怜')],\n",
       " 1980: [(0.3748411423736513, '巨额')],\n",
       " 1990: [(0.2683090578396913, '余下')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 示例用法\n",
    "get_seq_neighbor_with_pos(semb, pos_dict, \"钱\", \"ADJ\", n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a35a1c",
   "metadata": {},
   "source": [
    "## 读取词频（如果你需要的话）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a4951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文人: 2076.0\n",
      "作家: 210922.5\n",
      "反动: 44264.5\n"
     ]
    }
   ],
   "source": [
    "counts_file = '/root/workspace/MicroDistanc-Word2Vec/chi-sim-all/counts/1990-counts.pkl'\n",
    "with open(counts_file, 'rb') as f:\n",
    "    counts_dict = pickle.load(f, encoding='latin1') # 考虑到是python2时代保存的pickle文件，应该用latin1读取避免历史遗留问题\n",
    "\n",
    "# 示例：提取指定词的词频\n",
    "target_words = ['文人', '作家', '反动']\n",
    "for word in target_words:\n",
    "    print(f\"{word}: {counts_dict.get(word, '未知')}\")\n",
    "    \n",
    "# 如果你需要读取多个年代的词频，可自行编写相关代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cd680",
   "metadata": {},
   "source": [
    "## 加载数据集代码总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果读取单个时间点的数据：\n",
    "\n",
    "# from representations.embedding import Embedding\n",
    "# from representations.sequentialembedding import SequentialEmbedding\n",
    "\n",
    "# embedding = Embedding.load('这里放你的路径')\n",
    "\n",
    "\n",
    "# 如果读取多个时间点的数据：\n",
    "\n",
    "# years = range(1950, 2000, 10) # 这里放年份列表\n",
    "# semb = SequentialEmbedding.load('这里放你的文件夹路径', years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cdb28",
   "metadata": {},
   "source": [
    "## 英文数据集的加载也同理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31396cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from representations.sequentialembedding import SequentialEmbedding\n",
    "from representations.embedding import Embedding\n",
    "\n",
    "years = range(1800,2000,10)\n",
    "seq_embedding_eng = SequentialEmbedding.load('/root/workspace/MicroDistanc-Word2Vec/eng-all/sgns',years)\n",
    "# 加载比较慢，要忍一下"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
